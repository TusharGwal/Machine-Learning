# -*- coding: utf-8 -*-
"""Solution_3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/136Mk9AHfr_K6abfGCE_SrrHVlQe_Z1OF
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from matplotlib.cbook import boxplot_stats

# Read data from a space-delimited file
places_data = pd.read_csv('places.txt', delim_whitespace=True, header=None)

# Assign meaningful column names to the DataFrame
places_data.columns = ["Location", "Climate", "Housing", "Healthcare", "Crime", "Transportation",
                      "Education", "Arts", "Recreation", "Economic_Welfare", "A", "B", "C", "D", "E"]

# Display the DataFrame
places_data

"""Create a DataFrame named df1 to store the numerical values."""

data_frame = places_data.iloc[:,1:10]

"""We will now transform each value in the matrix by taking its natural logarithm with a base of 10."""

X = np.log10(data_frame.values)

"""The next step involves data centering, which starts by calculating the mean data vector, denoted as μ. Then, we subtract this mean vector from each data point. Once we have the centered data matrix, we utilize Singular Value Decomposition (SVD) to compute the principal components."""

u = X.mean(axis=0)
X = X - u
X[1:10,:]

X = np.log10(data_frame.values)

u = X.mean(axis=0)
X = X - u
X[1:10,:]

U,S,V = np.linalg.svd(X.T,full_matrices=True)

# Calculate the percentage of principal components
percentage_of_principles = (S / np.sum(S)) * 100

# Create a bar chart to visualize the percentage of principles
plt.bar(range(9), percentage_of_principles)
plt.ylabel("Percentage of Principal Components")
plt.xlabel("Dimensions")
plt.show()

principalComp =[X.dot(U[:,i].T) for i in range(9)]
v1 = principalComp[0]
v2 = principalComp[1]
v2.shape

C = pd.DataFrame({"v1":v1,"v2":v2})
C = pd.concat([places_data.iloc[:,:10],C], axis = 1)
C.corr().round(3).iloc[:9,9:]

"""Based on the analysis above, it's evident that v1 shows a negative correlation with healthcare and arts, while v2 doesn't exhibit strong correlations with any of the parameters.

Next, we proceed to project the data points onto the first two principal components, namely v1 and v2.
"""

plt.scatter(v1,v2)
plt.show()

"""We utilize the specified criteria to visualize the data points outliers."""

outliersIndex = []
i = 0
for x, y in zip(v1,v2):
    color = 'blue'
    if not -0.6 <= y <= 0.6 or not -1.5 <= x <=1.5:
        color = 'red'
        outliersIndex.append(i)
    i +=1
    plt.scatter(x, y, color=color)
plt.show()

"""Displaying the names and additional information of the outliers."""

outlierCities = [places_data.values[i,:] for i in outliersIndex]
pd.DataFrame(outlierCities)

"""**Part 6**"""

df = pd.read_csv('places.txt',delim_whitespace=True,header=None)
df.columns = ["Location", "climate", "housing", "healthcare", "crime", "transportation",
                                            "education", "arts", "recreation", "economic_welfare", "a", "b", "c", "d",
                                            "e"]
df

"""Creating a DataFrame, `df1`, by selecting numerical values."""

df1 = places_data.iloc[:,1:10]

"""Utilizing the DataFrame df1, we transform each element in the matrix into its respective Z-score."""

X = stats.zscore(df1.values, axis=0)
X[1:10,:]

"""Next, we begin by centering the data points. This involves calculating the mean data vector, denoted as μ, and then subtracting this mean from each individual data point. Once the data is centered, we proceed to perform a Singular Value Decomposition (SVD) to compute the principal components."""

u = X.mean(axis=0)
X = X - u
X[1:10,:]

U,S,V = np.linalg.svd(X.T,full_matrices=True)

# Calculate the percentage of principal components
percentage_of_principles = (S / np.sum(S)) * 100

# Create a bar chart to visualize the percentage of principles
plt.bar(range(9), percentage_of_principles)
plt.ylabel("Percentage of Principal Components")
plt.xlabel("Dimensions")
plt.show()

principalComp =[X.dot(U[:,i].T) for i in range(9)]
v1 = principalComp[0]
v2 = principalComp[1]
v2.shape

C = pd.DataFrame({"v1":v1,"v2":v2})
C = pd.concat([df.iloc[:,:10],C], axis = 1)
C.corr().round(3).iloc[:9,9:]

"""
Based on the analysis, it's evident that v1 exhibits correlations with healthcare and arts, while v2 is associated with education. Moving forward, we will project the data points onto the initial two principal components, namely v1 and v2."""

v1 = -v1
plt.scatter(v1,v2)
plt.show()

"""We utilize the specified condition to visualize the data points for outliers."""

outliersIndex = []
i = 0
for x, y in zip(v1,v2):
    color = 'blue'
    # if not min_threshold <= y <= max_threshold:
    # if not -0.6 <= y <= 0.6 or not -1.5 <= x <=1.5:
    if x>=3.5 or y>=2.9:
        color = 'red'
        outliersIndex.append(i)
    i +=1
    plt.scatter(x, y, color=color)
plt.show()

"""Displaying the names and additional information about the outliers."""

outlierCities = [df.values[i,:] for i in outliersIndex]
pd.DataFrame(outlierCities)

"""In the initial part of the query, the outliers were characterized as towns or villages, whereas in the z-scores analysis, the outliers are represented by cities."""