# -*- coding: utf-8 -*-
"""Solution_5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13GBnidx5k3p-3K_ufZSwpOGUcnHSCjy-
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import math
from sklearn.random_projection import GaussianRandomProjection, johnson_lindenstrauss_min_dim
from sklearn.metrics.pairwise import euclidean_distances

"""We create a data matrix X with parameters n = 10 and d = 5000, using the identity matrix of size d x d as a basis."""

matrix = np.identity(5000)
index = np.random.choice(matrix.shape[1], 10, replace=False)
X = matrix[index,:]

"""Set a constant value of ε to 0.1, and determine the embedding dimension, denoted as 'm,' by applying the relevant formula."""

n = 10
e = 0.1
denomi = (e**2 / 2) - (e**3 / 3)
m = 4*(np.log(n))/denomi
m.astype(np.int64)

"""Verifying the outcomes using the "johnson_lindenstrauss_min_dim" package."""

johnson_lindenstrauss_min_dim(n_samples=n, eps=0.1)

"""We will create a random projection matrix A with dimensions m × d."""

gaussianProjector = GaussianRandomProjection(n_components='auto',eps=0.1)
A = gaussianProjector.fit_transform(X)

"""Below verifies the shape of the resulting projection matrix"""

A.shape

"""We proceed to calculate the squared pairwise distances between pairs of vectors u and v, denoted as ∥u − v∥², as well as the squared pairwise distances between their projections, denoted as ∥Au − Av∥². Subsequently, we determine the absolute difference between these two sets of distances."""

X_dist = euclidean_distances(X)
A_dist = euclidean_distances(A)
A_X_diff = abs(X_dist - A_dist)

"""Below function returns the validtity of the Johnson-Lindenstrauss Lemma by monitoring the inequality

---


(1−ε) ∥u−v∥2 ≤ ∥Au−Av∥2 ≤ (1+ε)∥u−v∥2
"""

def JohnsonLindenstraussLemmaValidity(initial_matrix_dist,projected_matrix_dist,e):
  flag = True
  for i in range(0,len(initial_matrix_dist)):
    for j in range(0,len(initial_matrix_dist[0])):
      if ((1-e)*initial_matrix_dist[i][j] <= projected_matrix_dist[i][j] <= (1+e)*initial_matrix_dist[i][j]):
        continue
      else:
        flag = False
        break
  return "Johnson Lindenstrauss Lemma is valid" if flag else "Johnson Lindenstrauss Lemma is invalid"

"""We now check if the before calculated distance is valid with Johnson-Lindenstrauss Lemma"""

print(JohnsonLindenstraussLemmaValidity(X_dist,A_dist,e))

"""We iterate through the previously mentioned steps, progressively increasing the value of 'd' by a factor of 2 in each iteration while keeping 'm' and 'n' constant. This is done to assess the applicability of the Johnson-Lindenstrauss Lemma."""

e = 0.1
denomi = (e**2 / 2) - (e**3 / 3)
m = 4*(np.log(n))/denomi
n = 10
d = 5000

while True:
  d *= 2
  matrix = np.identity(d)
  index = np.random.choice(matrix.shape[1], 10, replace=False)
  X = matrix[index,:]
  gaussianProjector = GaussianRandomProjection(n_components='auto',eps=0.1)
  A = gaussianProjector.fit_transform(X)
  X_dist = euclidean_distances(X)
  A_dist = euclidean_distances(A)
  A_X_diff = abs(X_dist - A_dist)
  print(JohnsonLindenstraussLemmaValidity(X_dist,A_dist,e),"for d=",d)

"""The provided code encountered an error and crashed during its 5th iteration. The error message indicated that the session ran out of available RAM. If you require access to high-RAM runtimes, you might consider exploring Colab Pro as an option.

We iterate through the initial steps, incrementing 'n' by a factor of 2 while keeping 'd' constant. In each iteration, we calculate 'm' and verify its compliance with the Johnson-Lindenstrauss Lemma.
"""

e = 0.1
denomi = (e**2 / 2) - (e**3 / 3)
n = 10
d = 5000

while True:
  n *= 2
  m = 4*(np.log(n))/denomi
  matrix = np.identity(d)
  index = np.random.choice(matrix.shape[1], n, replace=False)
  X = matrix[index,:]
  gaussianProjector = GaussianRandomProjection(eps=0.1)
  A = gaussianProjector.fit_transform(X)
  X_dist = euclidean_distances(X)
  A_dist = euclidean_distances(A)
  A_X_diff = abs(X_dist - A_dist)
  print(JohnsonLindenstraussLemmaValidity(X_dist,A_dist,e),"for constant d=",d,"and n = ",n,"m calculated = ",m)

"""Based on the information provided, it's evident that the Johnson-Lindenstrauss Lemma holds true in all instances, subject to the constraint of error."""